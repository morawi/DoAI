{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"formatResullts.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPRuorVVVoQCHXefNjvGfRO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"M16kA64LLz_i"},"source":["Filenames for all txt files containing results for each model..."]},{"cell_type":"code","metadata":{"id":"-cimU3GELQpn"},"source":["files = [\"densenet121-cifar10-Fri-Apr--2-17-29-31-2021.txt\", \"densenet161-cifar10-Fri-Apr--2-21-11-54-2021.txt\",\n","             \"densenet169-cifar10-Sun-Apr--4-10-46-46-2021.txt\", \"densenet201-cifar10-Sat-Apr--3-09-44-31-2021.txt\",\n","             \"resnet18-cifar10-Fri-Apr--2-15-20-50-2021.txt\", \"resnet34-cifar10-Fri-Apr--2-19-41-47-2021.txt\",\n","             \"vgg11_bn-cifar10-Sat-Apr--3-12-02-13-2021.txt\", \"vgg13_bn-cifar10-Sun-Apr--4-07-18-41-2021.txt\",\n","             \"vgg16_bn-cifar10-Sat-Apr--3-20-02-39-2021.txt\", \"vgg19_bn-cifar10-Sun-Apr--4-00-32-57-2021.txt\",\n","             \"densenet121-cifar100-Sat-Apr--3-13-02-59-2021.txt\", \"densenet161-cifar100-Sat-Apr--3-14-50-43-2021.txt\",\n","             \"densenet169-cifar100-Sat-Apr--3-17-25-11-2021.txt\", \"densenet201-cifar100-Sat-Apr--3-21-54-52-2021.txt\",\n","             \"resnet18-cifar100-Fri-Apr--2-17-06-03-2021.txt\", \"resnet34-cifar100-Sun-Apr--4-12-01-57-2021.txt\",\n","             \"vgg11_bn-cifar100-Sun-Apr--4-11-02-31-2021.txt\", \"vgg13_bn-cifar100-Sun-Apr--4-14-59-35-2021.txt\",\n","             \"vgg16_bn-cifar100-Sun-Apr--4-18-55-01-2021.txt\", \"vgg19_bn-cifar100-Sun-Apr--4-23-28-28-2021.txt\",]\n","           "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f3l_JHdAMBjq"},"source":["Retrieves each line containing accuracy results from each epoch of training in each txt file..."]},{"cell_type":"code","metadata":{"id":"WF4s5yApMB6W"},"source":["for file in files:\n","    search = open(file)\n","    epochs = []\n","    for line in search:\n","        if '*' in line:\n","            line = line.replace(' * Acc@1 ', '')\n","            line = line.replace(' Acc@5', '')\n","            line = line.replace('\\n', '')\n","            epochs += line.split(' ')\n","            epochs1 = epochs[0:][::2]\n","            \n","    epochs1 = ', '.join(map(str, epochs1))\n","    print(epochs1)\n","    epochs5 = epochs[1:][::2]\n","    epochs5 = ', '.join(map(str, epochs5))\n","    print(epochs5)\n","\n","    text_file = open(\"new\" + file, \"wt\")\n","    text_file.write(epochs1 + \"\\n\")\n","    text_file.write(epochs5)\n","    text_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"icBgNiFpMTOf"},"source":["This code will then write to a new txt file for each of the models and will contain 100 comma delimited epoch results to be placed into the Excel spreadsheet. This is so the front end can visualize the learning process of each model through all its epochs."]}]}